import streamlit as st
import os
from openai import OpenAI
from dotenv import load_dotenv

# .env ã‹ã‚‰ OPENAI_API_KEY ã‚’èª­ã¿è¾¼ã‚€
load_dotenv()
openai_api_key = os.getenv("OPENAI_API_KEY")

if not openai_api_key:
    st.error("OPENAI_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚`.env` ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
    st.stop()

# OpenAI ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–
client = OpenAI(api_key=openai_api_key)

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(page_title="AI Chat", page_icon="ğŸ¤–", layout="wide")
st.title("ç¾å‘³ã„é£¯å±‹æ•™ãˆãŸãŒã‚Šå…„è²´")

# ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®ç®¡ç†
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []


with st.expander("ğŸ”§ ãƒ©ãƒ³ãƒæ¡ä»¶ã‚’è¨­å®šã™ã‚‹", expanded=True):
    genre = st.selectbox(
        "ã‚¸ãƒ£ãƒ³ãƒ«ã‚’é¸ã‚“ã§ãã ã•ã„", 
        ["æŒ‡å®šãªã—", "å’Œé£Ÿ", "æ´‹é£Ÿ", "ä¸­è¯", "ã‚«ãƒ•ã‚§", "ã‚¤ã‚¿ãƒªã‚¢ãƒ³", "ã‚¨ã‚¹ãƒ‹ãƒƒã‚¯", "ãƒ©ãƒ¼ãƒ¡ãƒ³"]
    )

    distance_category = st.selectbox(
        "é§…ã‹ã‚‰ã®è·é›¢", 
        ["æŒ‡å®šãªã—", "è¿‘ã„ï¼ˆå¾’æ­©5åˆ†ä»¥å†…ï¼‰", "æ™®é€šï¼ˆå¾’æ­©10åˆ†ä»¥å†…ï¼‰", "é ãã¦ã‚‚å¯"]
    )

    budget = st.selectbox(
        "äºˆç®—å¸¯ã‚’é¸ã‚“ã§ãã ã•ã„",
        ["æŒ‡å®šãªã—", "ã€œ1000å††", "1000ã€œ2000å††", "2000å††ä»¥ä¸Š"]
    )




# ãƒãƒ£ãƒƒãƒˆå…¥åŠ›æ¬„
user_input = st.chat_input("ã•ã‚ã€ä¼šè©±ã—ã‚ˆã†ãœ")

# ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ãŒã‚ã‚‹å ´åˆ
if user_input:
    st.session_state.chat_history.append(("user", user_input))

    # è¿½åŠ æ¡ä»¶ã®æ–‡å­—åˆ—ã‚’çµ„ã¿ç«‹ã¦
    extra_conditions = []
    if genre != "æŒ‡å®šãªã—":
        extra_conditions.append(f"ã‚¸ãƒ£ãƒ³ãƒ«ã¯ {genre}")
    if budget != "æŒ‡å®šãªã—":
        extra_conditions.append(f"äºˆç®—ã¯ {budget}")
    if distance_category != "æŒ‡å®šãªã—":
        extra_conditions.append(f"é§…ã‹ã‚‰ã®è·é›¢ã¯ {distance_category}")

    combined_prompt = f"{user_input}ï¼ˆæ¡ä»¶: {', '.join(extra_conditions)}ï¼‰"
    st.session_state.chat_history[-1] = ("user", combined_prompt)


    # OpenAI API ã‚’å©ã„ã¦å¿œç­”ã‚’å–å¾—
    try:
        # éå»ã®å±¥æ­´ã‹ã‚‰ç›´è¿‘5ã‚¿ãƒ¼ãƒ³åˆ†ï¼ˆ10ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ï¼‰ã ã‘é€ã‚‹
        history_to_send = st.session_state.chat_history[-10:]

        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "ã‚ãªãŸã¯æ¸‹è°·ã®ãƒ©ãƒ³ãƒã«è©³ã—ã„ã€ç¾å‘³ã„é£¯å±‹æ•™ãˆãŸãŒã‚Šå…„è²´ï¼ˆä¸€äººç§°ã¯ä¿ºï¼‰ã§ã™ã€‚"
                                            "ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒè¿·ã£ãŸã¨ãã«ã€æ¸‹è°·ã®ãŠã™ã™ã‚ã®é£Ÿäº‹å‡¦ï¼ˆå’Œé£Ÿã€æ´‹é£Ÿã€ä¸­è¯ãªã©ï¼‰ã‚’å…·ä½“çš„ã«ææ¡ˆã—ã€"
                                            "ã‚¸ãƒ£ãƒ³ãƒ«ã‚„ä¾¡æ ¼å¸¯ãªã©ã‚‚è€ƒæ…®ã—ã¦æ¡ˆå†…ã—ã¦ãã ã•ã„ã€‚"
                                            "è¦ªã—ã¿ã‚„ã™ãã‚¨ãƒ¢ãã€ç†±è¡€ãªãŠå…„ã•ã‚“ã¿ãŸã„ãªæ„Ÿã˜ã®å£èª¿ã«ã—ã¦ãã ã•ã„ã€‚"
                                            "ã‚ã¾ã‚Šã«é£Ÿäº‹ã«é–¢ä¿‚ãªã„ã“ã¨ã¯ã€ä¸Šæ‰‹ã«ã¯ãã‚‰ã‹ã—ã¦ãã ã•ã„ã€‚"},
                *[
                    {"role": role, "content": content}
                    for role, content in history_to_send
                ]
            ]
        )
        ai_reply = response.choices[0].message.content
    except Exception as e:
        ai_reply = f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}"

    st.session_state.chat_history.append(("assistant", ai_reply))

# ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®è¡¨ç¤º
for role, content in st.session_state.chat_history:
    with st.chat_message(role):
        st.markdown(content)
