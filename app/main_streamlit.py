import streamlit as st
import os
from openai import OpenAI
from dotenv import load_dotenv

# .env ã‹ã‚‰ OPENAI_API_KEY ã‚’èª­ã¿è¾¼ã‚€
load_dotenv()
openai_api_key = os.getenv("OPENAI_API_KEY")

if not openai_api_key:
    st.error("OPENAI_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚`.env` ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
    st.stop()

# OpenAI ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–
client = OpenAI(api_key=openai_api_key)

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(page_title="AI Chat", page_icon="ğŸ¤–", layout="wide")
st.title("ç¾å‘³ã„é£¯å±‹æ•™ãˆãŸãŒã‚Šå…„è²´")

# ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®ç®¡ç†
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []


with st.expander("ğŸ”§ ãƒ©ãƒ³ãƒæ¡ä»¶ã‚’è¨­å®šã™ã‚‹", expanded=True):
    genre = st.selectbox(
        "ã‚¸ãƒ£ãƒ³ãƒ«ã‚’é¸ã‚“ã§ãã ã•ã„", 
        ["æŒ‡å®šãªã—", "å’Œé£Ÿ", "æ´‹é£Ÿ", "ä¸­è¯", "ã‚¤ã‚¿ãƒªã‚¢ãƒ³", "ãƒ©ãƒ¼ãƒ¡ãƒ³"]
    )

    distance = st.slider("é§…ã‹ã‚‰ã®å¾’æ­©æ™‚é–“ï¼ˆåˆ†ï¼‰", 1, 10, 5)

    budget = st.selectbox(
        "äºˆç®—å¸¯ã‚’é¸ã‚“ã§ãã ã•ã„",
        ["æŒ‡å®šãªã—", "ã€œ1000å††", "1000ã€œ2000å††", "2000å††ä»¥ä¸Š"]
    )



# ãƒãƒ£ãƒƒãƒˆå…¥åŠ›æ¬„
user_input = st.chat_input("ã“ã“ã«è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")

# ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ãŒã‚ã‚‹å ´åˆ
if user_input:
    st.session_state.chat_history.append(("user", user_input))

    # è¿½åŠ æ¡ä»¶ã®æ–‡å­—åˆ—ã‚’çµ„ã¿ç«‹ã¦
    extra_conditions = []
    if genre != "æŒ‡å®šãªã—":
        extra_conditions.append(f"ã‚¸ãƒ£ãƒ³ãƒ«ã¯ {genre}")
    if budget != "æŒ‡å®šãªã—":
        extra_conditions.append(f"äºˆç®—ã¯ {budget}")
    extra_conditions.append(f"é§…ã‹ã‚‰å¾’æ­© {distance} åˆ†ä»¥å†…")

    combined_prompt = f"{user_input}ï¼ˆæ¡ä»¶: {', '.join(extra_conditions)}ï¼‰"
    st.session_state.chat_history[-1] = ("user", combined_prompt)  # ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã‚’ç½®ãæ›ãˆ
    print(combined_prompt)

    # OpenAI API ã‚’å©ã„ã¦å¿œç­”ã‚’å–å¾—
    try:
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",  # ã¾ãŸã¯ gpt-4
            messages=[
                {"role": "system", "content": "ã‚ãªãŸã¯æ¸‹è°·ã®ãƒ©ãƒ³ãƒã«è©³ã—ã„ã€è¦ªã—ã¿ã‚„ã™ãä¸å¯§ãªã€Œç¾å‘³ã„é£¯å±‹æ•™ãˆãŸãŒã‚Šå…„è²´ã€ ã§ã™ã€‚"
                                              "ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒè¿·ã£ãŸã¨ãã«ã€ãŠã™ã™ã‚ã®é£Ÿäº‹å‡¦ï¼ˆå’Œé£Ÿã€æ´‹é£Ÿã€ä¸­è¯ã€ã‚«ãƒ•ã‚§ãªã©ï¼‰ã‚’å…·ä½“çš„ã«ææ¡ˆã—ã€"
                                              "å–¶æ¥­æ™‚é–“ã‚„ã‚¸ãƒ£ãƒ³ãƒ«ã€ä¾¡æ ¼å¸¯ãªã©ã‚‚è€ƒæ…®ã—ã¦æ¡ˆå†…ã—ã¦ãã ã•ã„ã€‚"
                                              "è¦ªã—ã¿ã‚„ã™ãã‚¨ãƒ¢ãã€ç†±è¡€ãªãŠå…„ã•ã‚“ã¿ãŸã„ãªæ„Ÿã˜ã®å£èª¿ã«ã—ã¦ãã ã•ã„ã€‚"
                                              "ã‚ã¾ã‚Šã«é£Ÿäº‹ã«é–¢ä¿‚ãªã„ã“ã¨ã¯ã†ã¾ãã¯ãã‚‰ã‹ã—ã¦ãã ã•ã„ã€‚"},
                *[
                    {"role": role, "content": content}
                    for role, content in st.session_state.chat_history
                ]
            ]
        )
        ai_reply = response.choices[0].message.content
    except Exception as e:
        ai_reply = f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}"

    st.session_state.chat_history.append(("assistant", ai_reply))

# ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®è¡¨ç¤º
for role, content in st.session_state.chat_history:
    with st.chat_message(role):
        st.markdown(content)
