import os
from dotenv import load_dotenv
from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import OpenAIEmbeddings
from langchain_community.chat_models import ChatOpenAI
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate

load_dotenv()
api_key = os.getenv("OPENAI_API_KEY")

def load_vectorstore(path: str = "vectorstore/index"):
    embeddings = OpenAIEmbeddings(openai_api_key=api_key)
    return FAISS.load_local(path, embeddings, allow_dangerous_deserialization=True)

def build_rag_chain():
    vectorstore = load_vectorstore()
    retriever = vectorstore.as_retriever()

    llm = ChatOpenAI(
        model_name="gpt-3.5-turbo",
        temperature=0.7,
        openai_api_key=api_key
    )

    # ğŸ‘‡ å…„è²´Promptã‚’å®šç¾©
    system_prompt = (
        "ã‚ãªãŸã¯æ¸‹è°·ã®ãƒ©ãƒ³ãƒã«è©³ã—ã„ã€ç¾å‘³ã„é£¯å±‹æ•™ãˆãŸãŒã‚Šå…„è²´ï¼ˆä¸€äººç§°ã¯ä¿ºï¼‰ã§ã™ã€‚\n"
        "ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒè¿·ã£ãŸã¨ãã«ã€æ¸‹è°·ã®ãŠã™ã™ã‚ã®é£Ÿäº‹å‡¦ï¼ˆå’Œé£Ÿã€æ´‹é£Ÿã€ä¸­è¯ãªã©ï¼‰ã‚’å…·ä½“çš„ã«ææ¡ˆã—ã€\n"
        "ã‚¸ãƒ£ãƒ³ãƒ«ã‚„ä¾¡æ ¼å¸¯ãªã©ã‚‚è€ƒæ…®ã—ã¦æ¡ˆå†…ã—ã¦ãã ã•ã„ã€‚\n"
        "è¦ªã—ã¿ã‚„ã™ãã‚¨ãƒ¢ãã€ç†±è¡€ãªãŠå…„ã•ã‚“ã¿ãŸã„ãªæ„Ÿã˜ã®å£èª¿ã«ã—ã¦ãã ã•ã„ã€‚\n"
        "ã‚ã¾ã‚Šã«é£Ÿäº‹ã«é–¢ä¿‚ãªã„ã“ã¨ã¯ã€ä¸Šæ‰‹ã«ã¯ãã‚‰ã‹ã—ã¦ãã ã•ã„ã€‚\n\n"
        "ã€å‚è€ƒæƒ…å ±ã€‘\n{context}\n\nã€è³ªå•ã€‘\n{question}\n\nã€å…„è²´ã®å›ç­”ã€‘"
    )
    prompt = PromptTemplate.from_template(system_prompt)

    # ğŸ‘‡ RetrievalQA ã«Promptã‚’æ¸¡ã™
    qa_chain = RetrievalQA.from_chain_type(
        llm=llm,
        retriever=retriever,
        return_source_documents=True,
        chain_type_kwargs={"prompt": prompt}
    )

    return qa_chain
